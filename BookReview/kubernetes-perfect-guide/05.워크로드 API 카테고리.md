# 5장 워크로드 API 카테고리

# 5.1 워크로드 API 카테고리 개요

<img width="1003" alt="스크린샷 2024-08-18 오후 9 35 08" src="https://github.com/user-attachments/assets/7fdb9525-1266-4859-961b-1397daec37b4">

쿠버네티스 리소스는 크게 다섯 가지 카테고리로 분류되어 있는데 그 중 **워크로드 API 카테고리로 분류된 리소스는 클러스터에 컨테이너를 기동시키기 위해 사용되는 리소스**이다. 내부에서 사용되는 리소스를 제외하고, 사용자가 직접 사용하는 리소스는 총 여덟 가지다.

- 파드
- 레플리케이션 컨트롤러
- 레플리카셋
- 디플로이먼트
- 데몬셋
- 스테이트풀셋
- 잡
- 크론잡

파드를 최소 단위로 하여 그것을 관리하는 상위 리소스가 있는 부모 자식 관계로 되어 있다. 예를 들어, 디플로이먼트는 레플리카셋을 관리하고 레플리카셋은 파드를 관리한다.

# 파드(Pod)

<img width="727" alt="2" src="https://github.com/user-attachments/assets/971cafab-8933-4288-a718-17cb452eacd8">

워크로드 리소스의 최소 단위는 `파드(Pod)`라고 불리는 리소스다. 파드는 한 개 이상의 컨테이너로 구성되며, 같은 파드에 포함된 컨테이너끼리는 네트워크적으로 격리되어 있지 않고 IP 주소를 공유한다. 따라서 파드 내부의 컨테이너는 서로 localhost로 통신할 수 있다.

대부분의 경우 하나의 파드에 하나의 컨테이너를 가지지만 메인 컨테이너 이외에 프록시 역할을 하는 컨테이너, 설정값을 동적으로 변경시키는 컨테이너, 로컬 캐시용 컨테이너, SSL용 컨테이너 등 서브 컨테이너도 포함하여 여러 컨테이너를 가질 수도 있다. 하지만 nginx 컨테이너와 redis 컨테이너와 같은 메인 컨테이너를 하나의 파드 안에 두는 구성은 개별 파드의 이동이 어려워지고 복잡해지기 때문에 추천하지 않는다.

## 5.2.1 파드 디자인 패턴

파드 디자인 패턴에는 크게 세 종류가 있다. 이렇게 패턴이 구분되어 있지만, 보조적인 역할을 하는 서브 컨테이너를 통틀어 사이드카라고 부르는 경우도 있다.

### 사이드카 패턴(sidecar pattern)

<img width="744" alt="3" src="https://github.com/user-attachments/assets/bba28274-0eda-4a81-b22d-e231c22b1de9">

사이드카 패턴은 **메인 컨테이너 외에 보조적인 기능을 추가**하는 서브 컨테이너를 포함하는 패턴이다. 위 그림처럼 특정 변경 사항을 감지하여 동적으로 설정을 변경하는 컨테이너, 깃 저장소와 로컬 스토리지를 동기화하는 컨테이너, 애플리케이션의 로그 파일을 오브젝트 스토리지로 전송하는 컨테이너라는 구성이 자주 사용된다.

파드는 데이터 영역을 공유하고 가지고 있을 수 있기 때문에 대부분 데이터와 설정에 관련된 패턴이라 할 수 있다.

### 앰배서더 패턴(ambassador pattern)

<img width="856" alt="4" src="https://github.com/user-attachments/assets/5f6e27e5-f927-4926-95b4-b643c6a1a02d">

앰배서더 패턴은 메인 컨테이너가 외부 시스템과 접속할 때 대리로 중계해주는 서브 컨테이너(앰배서더 컨테이너)를 포함한 패턴이다. 파드에 두 개의 컨테이너가 있어 메인 컨테이너에 목적지에 localhost를 지정하여 앰배서더 컨테이너로 접속할 수 있다.

앰배서더 컨테이너를 사용하지 않고 메인 컨테이너에서 샤딩(sharding)된 데이터베이스 하나를 선택하여 접속하게 된다면 메인 컨테이너는 데이터베이스와의 결합도가 강해진다. 그러나 앰배서더 컨테이너를 사용함으로써 메인 컨테이너에서는 항상 localhost를 지정하여 앰배서더 컨테이너로만 접속하고 앰배서더 컨테이너가 여러 목적지에 중계하여 연결하도록 구성하면 느슨한 결합을 유지할 수 있다.

### 어댑터 패턴(adapter pattern)

<img width="857" alt="5" src="https://github.com/user-attachments/assets/035f4d51-8a6d-4136-a54d-6c13e42ac0d8">

어댑터 패턴은 서로 다른 데이터 형식을 변환해주는 컨테이너(어댑터 패턴)를 포함하는 패턴이다. 예를 들어, 프로메테우스(Prometheus) 등의 모니터링 소프트웨어에서는 정의된 형식으로 매트릭을 수집해야 한다. 그러나 대부분의 미들웨어가 제공하는 메트릭 출력 형식은 프로메테우스 메트릭 형식을 지원하지 않는다. 따라서 이러한 경우 어댑터 컨테이너를 사용하면 외부 요청에 맞게 데이터 형식으로 변환하고 데이터를 반환해준다. 어댑터 패턴의 경우도 메인 컨테이너와 어댑터 컨테이너 간에는 localhost를 통해 접속할 수 있다.

## 5.2.2 파드 생성

```yaml
apiVersion: v1
kind: Pod
metadata:
	name: sample-pod
spec:
	containers:
	- name: nginx-container
		image: nginx:1.16
```

```yaml
# 파드 생성
kubectl apply -f sample-pod.yaml

# 파드 목록 표시
kubectl get pods

# 파드 상세 정보 표시
kubectl get pods --output wide
```

sample-pod 내부에 `nginx:1.16` 이미지를 사용한 컨테이너 하나를 기동하고 80/TCP 포트를 바인드하는 단순한 파드이다.

## 5.2.3 두 개의 컨테이너를 포함한 파드 생성

```yaml
apiVersion: v1
kind: Pod
metadata:
	name: sample-pod
spec:
	containers:
	- name: nginx-container
		image: nginx:1.16
	- name: redis-container
		image: redis:3.2
```

위 매니페스트는 nginx와 redis라는 두 개의 컨테이너를 가진 파드 예제이다. 레디스(redis)sms 6379/TCP 포트를 바인드한다. 물론, nginx나 redis와 같은 메인 컨테이너를 하나의 파드 안에 같이 구성하는 것은 추천하지 않는다.

### 같은 포트를 사용하는 두 개의 컨테이너를 가진 파드 예제

```yaml
apiVersion: v1
kind: Pod
metadata:
	name: sample-pod-fail
spec:
	containers:
	- name: nginx-container-112
		image: nginx:1.16
	- name: nginx-container-113
		image: nginx:1.17
```

```yaml
# 포트 충돌이 있는 파드 생성
kubectl apply -f sample-pod-fail.yaml

# 파드 상태가 에러임을 확인
kubectl get pods

# 파드 로그 확인(여러 컨테이너가 있는 경우 특정 컨테이너 지정 가능)
kubectl logs sample-pod-fail -c nginx-container-113
```

<img width="1091" alt="6" src="https://github.com/user-attachments/assets/c332a903-eb8c-4c2e-b751-35af0ec0495b">

<img width="760" alt="7" src="https://github.com/user-attachments/assets/f471caf3-ed3a-4e2f-b997-6dbd0a900609">

파드는 네트워크 네임스페이스를 공유하고 있으므로, 일반 VM상에 80/TCP 포트를 바인드하는 서비스를 하나 이상 사용할 수 없는 환경과 같다고 보면 된다. 파드 내에서 containerPort가 충돌하지 않도록 해야 한다.

## 5.2.4 컨테이너 로그인과 명령어 실행

컨테이너 로그인이라고 하는 것은 실제 ssh와 같이 컨테이너에 직접 로그인하는 것이 아닌 가상 터미널을 생성(`-t`)하고, 표준 입력을 패스 스루(`-i`)하면서 `/bin/sh`를 실행하면 마치 컨테이너에 ssh로 로그인한 상태가 된다. 실제로 컨테이너에 로그인하여 확인하려면 `kubectl exec`에서 bash를 실행한다.

```bash
# 컨테이너에서 /bin/bash 실행
kubectl exec -it sample-pod -- /bin/bash
root@sample-pod:/# (이후부터 컨테이너 내부에서 명령어 실행 가능)

# 확인 작업에 필요한 패키지 설치
apt update && apt -y install iproute2 procps

# 컨테이너 내부에서 바인드(listen)하는 포트 확인
ss -napt | grep LISTEN

# 컨테이너 내부에서 프로세스 확인
ps aux
```

<img width="998" alt="8" src="https://github.com/user-attachments/assets/28743094-383c-4747-a136-90df20a397cc">

이외에도 `kubectl exec -it sample-pod --some-command`처럼 여러 가지 명령어를 실행할 수 있다.

```bash
# 컨테이너에서 ls 명령어 실행
kubectl exec -it sample-pod -- /bin/ls

# 다수의 컨테이너를 포함한 파드의 경우 특정 컨테이너 지정 가능
kubectl exec -it sample-2pod -c nginx-container -- /bin/ls

# 옵션을 포함한 명령어 실행
kubectl exec -it sample-pod -- /bin/ls --all --classify

# 파이프 등 특정 문자열을 포함한 경우의 실행
kubectl exec -it sample-pod -- /bin/bash -c "ls -all --classify | grep lib"
```

## 5.2.5 ENTRYPOINT 명령/CMD 명령과 command/args

```yaml
apiVersion: v1
kind: Pod
metatdata:
	name: sample-entrypoint
spec:
	containers:
	- name: nginx-container-112
		image: nginx:1.16
		command: ["/bin/sleep"] # ENTRYPOINT 명령으로 대체
		args: ["3600"] # CMD 명령으로 대체
```

쿠버네티스에서는 도커용 용어와 조금 다르게 ENTRYPOINT를 `command`, CMD를 `args`라고 부른다. 컨테이너를 실행할 때 도커 이미지의 ENTRYPOINT와 CMD를 덮어 쓰기하려면 파드 정의 내용 중 spec.containers[].command와 spec.containers[].args를 지정한다.

## 5.2.6 파드명 제한

쿠버네티스에서는 파드명에 제한이 있다. 파드명은 RFC1123의 호스트명 규약을 따르고 있어 다음 조건에 맞아야 한다.

- 이용 가능한 문자는 영어 소문자와 숫자
- 이용 가능한 기호는 `-` 또는 `.`
- 시작과 끝은 영문 소문자

## 5.2.7 호스트의 네트워크 구성을 사용한 파드 기동

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: sample-pod
spec:
  hostNetwork: true
  containers:
    - name: nginx-container
      image: nginx:1.16
```

쿠버네티스에 기동하는 파드에 할당된 IP 주소는 쿠버네티스 노드의 호스트 IP 주소와 범위가 달라 외부에서 볼 수 없는 IP 주소가 할당된다. 호스트의 네트워크를 사용하는 설정(spec.hostNetwork)을 활성화하면 호스트상에서 프로세스를 기동하는 것과 같은 네트워크 구성(IP 주소, DNS 설정, host 설정 등)으로 파드를 기동시킬 수 있다.

hostNetwork를 사용한 파드는 쿠버네티스 노드의 IP 주소를 사용하는 관계로 포트 번호 충돌을 방지하기 위해 기본적으로 사용하지 않고 NodePort 서비스 등으로 해결할 수 있는지 검토하는 것이 좋다.

```bash
# 파드의 IP 주소 확인
kubectl get pod sample-hostnetwork -o wide

# 파드가 기동 중인 노드의 IP 주소 확인
kubectl get node minikube -o wide

# 파드의 호스트명 확인
kubectl exec -it sample-hostnetwork -- hostname

# 파드의 DNS 설정 확인
kubectl exec -it sample-hostnetwork -- cat /etc/resolv.conf
```

<img width="1220" alt="9" src="https://github.com/user-attachments/assets/268159ae-e0fa-4c21-a3ed-c679e7b11847">

## 5.2.8 파드 DNS 설정과 서비스 디스커버리

DNS 서버에 관한 설정(dnsPolicy)은 파드 정의(spec.dnsPolicy)에 설정한다.

### ClusterFirst(기본값)

```bash
# 컨테이너 내부의 DNS 설정 파일 /etc/resolv.conf를 표시
kubectl exec -it sample-dnspolicy-clusterfirst -- cat /etc/resolv.conf

# 클러스터 내부의 DNS Service에 할당된 IP 주소를 확인
kubectl get services -n kube-system
```

일반적으로 파드는 클러스터 내부 DNS를 사용하여 이름을 해석한다. 이는 서비스 디스커버리나 클러스터 내부 로드 밸런싱에서 사용하기 위해서다. dnsPolicy가 ClusterFirst인 경우 클러스터 내부의 DNS 서버에 질의를 하고, 클러스터 내부 DNS에서 해석이 안 되는 도메인에 대해서는 업스트림 DNS 서버에 질의한다.

<img width="1273" alt="1" src="https://github.com/user-attachments/assets/4976ab4e-d844-4814-8838-5b47d940ae4c">

### None

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: sample-dnspolicy-none
spec:
  dnsPolicy: None
  dnsConfig:
    nameservers:
    - 8.8.8.8
    - 8.8.4.4
    searches:
    - example.com
    options:
    - name: ndots
      value: "5"
  containers:
    - name: nginx-container
      image: nginx:1.16
```

Nond은 파드 정의 내에서 정적으로 설정한다. 특별한 요건에 따라서는 클러스터 외부 DNS 서버를 참조하는 경우도 있다. DNS 서버를 수동으로 설정하려면 spec.dnsPolicy: None이라고 설정한 후 dnsConfig에 설정하고 싶은 값을 작성하면 된다. 정적으로 외부 DNS 서버만 설정하면 클러스터 내부 DNS를 사용한 서비스 디스커버리는 사용할 수 없으므로 주의해야 한다.

<img width="1215" alt="2" src="https://github.com/user-attachments/assets/4b386554-22bf-41cf-b35c-7768fb036417">

### Default

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: sample-dnspolicy-default
spec:
  dnsPolicy: Default
  containers:
    - name: nginx-container
      image: nginx:1.16
```

쿠버네티스 노드의 DNS 설정을 그대로 상속받는 경우에 사용한다. 파드가 기동하는 쿠버네티스 노드의 `/etc/resolv.conf`를 상속받는다. 위와 같이 파드를 생성하면 쿠버네티스 노드의 `/etc/resolv.conf`와 똑같은 내용을 확인할 수 있다. 쿠버네티스 노드의 DNS 설정을 상속받게 설정하면 클러스터 내부의 DNS를 사용한 서비스 디스커버리를 할 수 없게 되므로 주의해야 한다.

<img width="1253" alt="3" src="https://github.com/user-attachments/assets/7fd0c64f-488e-477e-bce1-530d030147c4">

### ClusterFirstWithHostNet

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: sample-dnspolicy-clusterfirstwithhostnet
spec:
  dnsPolicy: ClusterFirstWithHostNet
  hostNetwork: true
  containers:
    - name: nginx-container
      image: nginx:1.16
```

hostNetwork를 사용한 파드에 클러스터 내부의 DNS를 참조하고 싶은 경우에 설정한다. hostNetwork를 사용하는 경우 기본값 Clusterfirst의 설정값은 무시되고 쿠버네티스 노드의 네트워크 설정(DNS 설정 포함)이 사용되기 때문에 명시적으로 ClusterFirstWithHostNet을 지정하도록 하자.

<img width="1548" alt="4" src="https://github.com/user-attachments/assets/785745fd-600f-43f0-8d9b-3c549cb6c00b">

## 5.2.9 정적 호스트명 해석 설정: /etc/hosts

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: sample-hostaliases
spec:
  containers:
    - name: nginx-container
      image: nginx:1.16
    hostAliases:
    - ip: 8.8.8.8
      hostnames:
      - google-dns
      - google-public-dns
```

리눅스 운영체제에서는 DNS로 호스트명을 해석하기 전에 `/etc/hosts` 파일로 정적 호스트명을 해석한다. 쿠버네티스에서는 파드 내부 모든 컨테이너의 `/etc/hosts`를 변경하는 기능이 준비되어 있으며 `spec.hostAliases`로 지정하여 사용할 수 있다.

<img width="1327" alt="5" src="https://github.com/user-attachments/assets/ceed1f88-c243-462a-a5bc-bde77db900bb">

실제로 생성한 파드 내부의 `/etc/hosts`를 확인해보면 spec.ohstAliases에서 지정한 내용이 추가된 것을 확인할 수 있다.

## 5.2.10 작업 디렉터리 설정

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: sample-hostaliases
spec:
  containers:
    - name: nginx-container
      image: nginx:1.16
    workingDir: /tmp
```

컨테이너에서 동작하는 애플리케이션의 작업 디렉터리는 도커 파일의 `WORKDIR` 명령 설정을 따르지만 `spec.containers[].workingDir`로 덮어 쓸 수도 있다. 예를 들어, 볼륨 기능을 사용하여 특정 스크립트 등이 배치된 볼륨을 파드에 마운트할 때 그 스크립트가 배치된 디렉터리로 이동한 후 실행하고 싶은 경우에 사용할 수 있다.

<img width="1216" alt="6" src="https://github.com/user-attachments/assets/5caf29b1-eed1-41c8-8d2d-114dc795913a">

# 5.3 레플리카셋(ReplicaSet)/레플리케이션 컨트롤러(ReplicationController)

<img width="772" alt="7" src="https://github.com/user-attachments/assets/0a99b6bf-fa49-43a8-9568-089d01cf4be4">

레플리카셋/레플리케이션 컨트롤러는 파드의 레플리카를 생성하고 지정한 파드 수를 유지하는 리소스다. 원래 파드의 레플리카를 생성하는 리소스의 이름은 레플리케이션 컨트롤러였는데, 시간이 지나 레플리카셋으로 이름이 변경되면서 일부 기능이 추가되었다. 레플리케이션 컨트롤러는 앞으로 사용하지 않는 추세이기 때문에 기본적으로 레플리카셋을 사용하자.

## 5.3.1 레플리카셋 생성

```yaml
apiVersion: v1
kind: ReplicaSet
metadata:
  name: sample-rs
spec:
  replicas: 3
  selector:
    matchLabels:
      app: sample-app
  template:
    metadata:
      labels:
        app: sample-app
  containers:
    - name: nginx-container
      image: nginx:1.16
```

`spec.template` 부분에는 복제할 파드 정의(Pod Template)를 기술한다. 생성한 파드를 레플리카 수 3으로 확장시킨 레플리카셋을 생성한다.

```bash
# 레플리카셋 생성
kubectl apply -f sample-rs.yaml

# 레플리카셋 확인
kubectl get replicasets -o wide

# 레플리카셋이 파드 관리에 사용하는 레이블(app=sample-app)을 지정하여 파드 목록 표시
kubectl get pods -l app=sample-app
```

<img width="1294" alt="8" src="https://github.com/user-attachments/assets/9825ba13-e2d2-4580-a100-4e24e45a61e2">

레플리카셋을 확인해보면 세 개의 파드가 기동 중인 것을 확인할 수 있다. 실제로 레이블을 지정하여 파드를 확인해 봐도 기동 중인 세 개의 파드를 확인할 수 있다. 배포된 노드를 보면, 파드가 각각 다른 노드에 흩어져 생성되어 있기 때문에 만약 노드에 장애가 발생하더라도 서비스에 미치는 영향을 최소화할 수 있다.

또한, 레플리카셋이 생성하는 파드는 `레플리카셋 이름-임의의 문자열`로 명명된다.

## 5.3.2 파드 정지와 자동화된 복구

<img width="781" alt="9" src="https://github.com/user-attachments/assets/082a8d09-e03e-4258-8a95-18dce6cfa1f6">

레플리카셋에서는 노드나 파드에 장애가 발생했을 때 지정한 파드 수를 유지하기 위해 다른 노드에서 파드를 기동시켜 주기 때문에 장애 시에도 많은 영향을 받지 않는다. 이는 쿠버네티스의 중요한 콘셉트 중 하나로, `자동화된 복구`라는 기능이다.

```bash
# 파드 정지(삭제)
# 실제 기동 중인 파드명을 지정
kubectl delete pod sample-rs-g6cpz

# 레플리카셋 목록 표시
kubectl get pods -o wide

# 레플리카 상세 정보 표시
kubectl describe replicaset sample-rs
```

자동화된 복구의 동작을 확인하기 위해 테스트로 파드 한 대를 정지시키고, 다시 파드를 확인하면 즉시 레플리카셋에 의해 파드가 새로 생성되는 것을 확인할 수 있다.

레플리카셋의 파드 수 증갑 이력은 `kubectl describe rs` 명령어로 확인할 수 있다.

<img width="1231" alt="1" src="https://github.com/user-attachments/assets/4753341d-b2b0-4099-aca2-1d0702633957">

<img width="1247" alt="2" src="https://github.com/user-attachments/assets/d052242a-3308-4df1-8616-99724582382b">

## 5.3.3 레플리카셋과 레이블

<img width="877" alt="3" src="https://github.com/user-attachments/assets/0d65d5bd-5807-4ad8-a734-5b865413d8d7">
레플리카셋은 쿠버네티스가 파드를 모니터링하여 파드 수를 조정한다. 모니터링은 특정 레이블을 가진 파드 수를 계산하는 형태로 이루어진다. 레플리카 수가 부족한 경우 매니페스트에 기술된 `spec.template`로 파드를 생성하고 레플리카 수가 많은 경우 레이블이 일치하는 파드 중 하나를 삭제한다.

```yaml
selector:
	matchLabels:
		app: sample-app
template:
  metadata:
    labels:
      app: sample-app
```

어떤 레이블을 가진 파드를 계산할지는 다음과 같이 `spec.selector` 부분에 지정한다. `spec.template.metadata.labels` 부분에 해당하는 `app: sample-app` 레이블을 설정하고 `app: sample-app` 레이블이 지정된 상태에서 파드가 생성되었기 때문에 레플리카 수로 계산된다.

### selector와 template 불일치한 상태로 생성하려는 경우

<img width="984" alt="4" src="https://github.com/user-attachments/assets/961fd1f5-bc06-4b92-bf66-e7329c80d6c3">

```yaml
apiVersion: v1
kind: ReplicaSet
metadata:
  name: sample-rs-fail
spec:
  replicas: 3
  selector:
    matchLabels:
      app: sample-app
  template:
    metadata:
      labels:
        app: sample-app-fail
  containers:
    - name: nginx-container
      image: nginx:1.16
```

`spec.selector`와 `spec.template.metadata.labels`의 레이블이 일치하지 않으면 어떻게 될까?

```yaml
# 레이블 불일치 상태로 생성
kubectl apply -f sample-rs-fail.yaml

# The ReplicaSet "sample-rs-fail" is invalid: spec.template.metadata.labels: Invalid value: map[string]string{"app":"sample-app-fail"}:
# `selector` does not match template `labels`
```

레이블이 일치하지 않는 경우 에러가 발생하여 생성할 수 없게 되어있다. 만약 에러가 발생하지 않는다면 레플리카 수를 늘리려고 파드가 계속 생성될 것이다.

### 레플리카셋의 셀렉터와 일치하는 레이블을 가진 파드 생성하는 경우

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: sample-rs
  lables:
    app: sample-app
containers:
  - name: nginx-container
    image: nginx:1.16
```

위와 같이 레플리카 수를 3으로 지정한 sample-rs.yaml과 같은 레이블(app: sample-app)을 가진 sample-rs-pod를 생성하고 테스트해보자.

```bash
kubectl apply -f sample-rs.yaml
kubectl apply -f sample-rs-pod.yaml
```

생성 후 파드의 상태를 확인해보자. `kubectl get pods -L` 옵션을 사용하면 각 파드에 지정된 레이블도 표시할 수 있다. 

<img width="994" alt="5" src="https://github.com/user-attachments/assets/c45ddb36-b4ab-49f4-b235-374f502552fe">

## 5.3.4 레플리카셋과 스케일링

### 매니페스트를 수정하여 kubectl apply -f 명령어를 실행

```bash
sed -i -e 's|replicas: 3|replicas: 4|' sample-rs.yaml
kubectl apply -f sample-rs.yaml
```

<img width="1364" alt="6" src="https://github.com/user-attachments/assets/0fc95ae6-90b7-4f1d-ac21-b5143b267a3c">

첫 번째 방법인 매니페스트를 수정하여 kubectl apply 명령어를 실행하는 방법인데 IaC(Infrastructure as Code)를 구현하기 위해서라도 이 방법을 사용하는 것이 좋다.

### kubectl scale 명령어를 사용하여 스케일 처리

두 번째 방법은 kubectl scale 명령어를 사용하여 스케일링하는 방법이다. scale 명령어를 사용한 스케일 처리는 레플리카 셋 이외에도 레플리케이션 컨트롤러/디플로이먼트/스테이트풀셋/잡/크론잡에서 사용할 수 있다.

```bash
# 레플리카 수를 5로 변경
kubectl scale replicaset sample-rs --replicas 5

# 레플리카셋 목록 표시
kubectl get replicats
```

<img width="1330" alt="7" src="https://github.com/user-attachments/assets/24999690-5e30-4406-a2c0-7bd3402d0414">

## 5.3.5 일치성 기준 조건과 집합성 기준 조건

레플리카 제어 조건은 서비스 중단 예정인 레플리케이션 컨트롤러의 일치성 기준(equality-based) 셀렉터였지만, 레플리카셋에서는 좀 더 강화된 집합성 기준(set-based) 셀렉터를 사용하여 유연한 제어도 가능하다. 쿠버네티스에서 어떤 조건을 지정할 때는 이 두 가지 방법이 있고 레플리카셋 외에 스케줄링할 때도 이 조건 지정이 사용된다.

- 일치성 기준
    - 조건부에 일치 불일치(`=`, `!=`) 조건 지정
- 집합성 기준
    - 조건부에 일치 불일치(`=`, `!=`) 조건 지정과 집합(`in`, `notin`, `exists`) 조건 지정 기능

일치성 기준 조건에서는 조건부에서 같은지 혹은 같지 않은지에 대한 조건을 사용할 수 있다. 예를 들어, `app=sample-app`과 같이 지정한다. 집합성 기준 조건에서는 일치성 기준 조건과 함께 집합 조건을 지정할 수 있다. 예를 들어, `env In [development, staging]`과 같이 지정할 수 있따. 또 `In` 연산자는 스케줄링 조건에서 사용할 때 수치 비교도 가능하다.

# 5.4 디플로이먼트(Deployment)

<img width="1214" alt="1" src="https://github.com/user-attachments/assets/a0c48091-52c1-4423-9bb4-014941f5bc8d">

디플로이먼트는 여러 레플리카셋을 관리하여 롤링 업데이트나 롤백 등을 구현하는 리소스다. 디플로이먼트가 레플리카셋이 파드를 관리하는 관계다. 간단한 구조이며, 다음과 같은 순서로 동작한다.

1. 신규 레플리카셋을 생성
2. 신규 레플리카셋의 레플리카 수(파드 수)를 단계적으로 늘림
3. 이전 레플리카셋의 레플리카 수(파드 수)를 단계적으로 줄임
4. (2, 3을 반복)
5. 이전 레플리카셋은 레플리카 수를 0으로 유지

디플로이먼트를 사용하면 신규 레플리카셋에 컨테이너가 기동되었는지와 헬스 체크는 통과했는지를 확인하면서 전환 작업이 진행되며, 레플리카셋의 이행 과정에서 파드 수에 대한 상세한 지정도 가능하다. 이는 쿠버네티스에서 가장 권장하는 컨테이너 기동 방법으로 알려져 있다. 하나의 파드를 기동만 한다하더라도 디플로이먼트 사용을 권장한다. 파드로만 배포한 경우에는 파드에 장애 발생 시 자동 생성이 되지 않으며, 레플리카셋으로만 배포한 경우에는 롤링 업데이트 등의 기능을 사용할 수 없다.

## 5.4.1 디플로이먼트 생성

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sample-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: sample-app
  template:
    metadata:
      labels:
        app: sample-app
    spec:
      containers:
      - name: nginx-container
        image: nginx:latest
```

```yaml
# --record 옵션을 사용하면 어떤 명령어를 업데이트했는지 이력을 저장해둔다.
kube apply -f sample-deployment.yaml --record

# 레플리카셋 목록을 YAML 형식으로 표시
kubectl get replicasets -o yaml | head
```

<img width="1104" alt="2" src="https://github.com/user-attachments/assets/f4a84a8d-7ecf-4e8a-8e48-65a3c763fbb7">

이력은 각 레플리카셋의 metadata.annotations[kubernetes.io/change-cause]에 저장되어 있다. 또한, 현재 레플리카셋의 수정 번호도 마찬가지로 meta.annotations[deployment.kubernetes.io/revision]에 저장되어 있다.

디플로이먼트를 확인해보면 레플리카셋과 거의 같은 정보가 표시된다. 이름을 봐도(명명 규칙) 디플로이먼트가 레플리카셋을 생성하고 레플리카셋이 파드를 생성한다는 것을 알 수 있다.

```yaml
# 컨테이너 이미지 업데이트
kubectl set image deployment sample-deployment nginx-container=nginx:1.17 --record

# 디플로이먼트 업데이트 상태 확인
kubectl rollout status deployment sample-deployment
```

<img width="1104" alt="2" src="https://github.com/user-attachments/assets/1f181d09-af90-4d97-8342-1b46fe596659">

테스트로 디플로이먼트가 사용하는 컨테이너 이미지를 nginx:1.16에서 nginx:1.17로 업데이트해보자.

업데이트 후 레플리카셋이 새롭게 생성되고 거기에 연결되는 형태로 파드도 다시 생성된다. 이때 내부적으로 롤링 업데이트가 되기 때문에 실제 서비스에는 영향이 없다.

<img width="1217" alt="4" src="https://github.com/user-attachments/assets/5b39b4d8-5abf-456b-a517-353e9e490a9a">

## 디플로이먼트 업데이트(레플리카셋이 생성되는) 조건

<img width="1228" alt="5" src="https://github.com/user-attachments/assets/35be7dea-2e29-427d-b6ef-0e3b32a65cc9">

위에서 봤듯이 디플로이먼트에서 변경이 발생하면 레플리카셋이 생성된다. `spec.template`에 변경이 있으면 생성된 파드의 설정이 변경되기 때문에 레플리카셋을 신규로 생성하고 롤링 업데이트를 하게 된다. 실제로 매니페스트를 쿠버네티스에 등록한 후 레플리카셋의 정의를 보면, `spec.teamplate` 아래의 해시값(파드 템플릿 해시(Pod Template Hash))을 계산하고, 이 값을 사용한 레이블로 관리한다. 다시 수작업으로 이미지 등을 이전버전으로 재변경하여 해시값이 동일해진 경우에는 레플리카셋을 신규로 생성하지 않고 기존 레플리카셋을 사용한다.

## 5.4.3 변경 롤백

<img width="1246" alt="6" src="https://github.com/user-attachments/assets/df026fca-4a11-427f-9c4b-2ef265299550">

디플로이먼트에는 롤백 기능이 있다. 롤백 기능의 실체는 혀재 사용 중인 레플리카셋의 전환과 같은 것이다. 디플로이먼트가 생성한 기존 레플리카셋은 레플리카 수가 0인 상태로 남아있기 때문에 레플리카 수를 변경시켜 다시 사용할 수 있는 상태가 된다.

```yaml
# 변경 이력 확인
kubectl rollout history deployment sample-deployment

# 해당 수정 버전에 대한 상세한 정보를 가져오려면 --revision 옵션을 지정한다.
# 초기 상태의 디플로이먼트
kubectl rollout history deployment sample-deployment --revision 1
```

<img width="1120" alt="7" src="https://github.com/user-attachments/assets/25adc71b-4d07-4721-a1d7-f0c8e59892f5">

변경 이력을 확인할 때는 `kubectl rollout history` 명령어를 사용한다. `CHANGE-CAUSE` 부분은 디플로이먼트를 생성할 때 `--record` 옵션을 사용하여 이력 내용이 있지만, `--record` 옵션을 사용하지 않았다면 `<none>` 등이 된다.

```yaml
# 버전 번호를 지정하여 롤백하는 경우
kubectl rollout undo deployment sample-deployment --to-revision 1

# 바로 이전 버전으로 롤백하는 경우(기본값인 --to-revison 0이 지정되어 바로 이전 버전으로 롤백)
kubectl rollout undo deployment sample-deployment

# 롤백한 후 이전 레플리카셋에서 파드가 기동됨
kubectl get replicasetsf
```

<img width="1106" alt="8" src="https://github.com/user-attachments/assets/dab93bc5-2aec-4351-afca-722636704276">

롤백하려면 `kubectl rollout undo`를 사용한다. 명령어의 인수로 버전 번호를 지정할 수 있으며, 0으로 지정하거나 지정하지 않을 경우에는 바로 이전 버전으로 롤백하게 된다. 롤백한 후에는 이전 레플리카셋의 파드가 기동된다.

실제 환경에서는 롤백 기능을 사용하는 경우가 많지 않다. CI/CD 파이프라인에서 롤백을 하는 경우 `kubectl rollout` 명령어보다 이전 매니페스트를 다시 `kubectl apply` 명령어로 실행하여 적용하는 것이 호환성 면에서 더 좋기 때문이다. 이때 `spec.template`을 같은 내용으로 되돌렸을 경우에는 `pod-template-hash` 값이 같기 때문에 `kubectl rollout`처럼 기존에 있던 레플리카셋의 파드가 기동된다.

## 5.4.4 디플로이먼트 변경 일시 중지

```yaml
# 업데이트 일시 중지
kubectl rollout pause deployment sample-deployment

# 업데이트 일시 정지 해제
kubectl rollout resume deployment sample-deployment

# pause 상태에서 컨테이너 이미지 업데이트
kubectl set image deployment sample-deployment nginx-container=nginx:1.16

# 업데이트는 대기 상태
kubectl rollout status deployment sample-deployment

# pasu된 상태에서 롤백 -> 롤백되지 않는다.
kubectl rollout undo deployment sample-deployment
```

<img width="1137" alt="9" src="https://github.com/user-attachments/assets/f6996e24-e52a-46e5-81b2-dc83f44cc868">

일반적으로 디플로이먼트를 업데이트하면 바로 적용되어 업데이트 처리가 실행된다. 그러나 안전을 위해 디플로이먼트에 대한 업데이트를 하더라도 바로 적용되지 않는 것을 원하는 경우도 있다. 이런 경우를 위해 즉시 적용을 일시 정지하고 싶을 떄는 `kubectl rollout pause`를 실행하고, 다시 시작할 때는 `kubectl rollout resume`을 실행한다.

## 5.4.5 디플로이먼트 업데이트 전략

디플로이먼트를 업데이트하면 기본적으로 롤링 업데이트가 실행되었다. 업데이트 전략을 지정하는 `spec.strategy.type`이라는 항목의 기본값이 `RollingUpdate`로 되어있기 때문이다. 업데이트 전략에는 `Recreate`와 `RollingUpdate`가 있다.

### Recreate

<img width="1009" alt="1" src="https://github.com/user-attachments/assets/06857402-2a67-4704-a382-3f7ea8638c7d">

Recreate는 모든 파드를 한 번 삭제하고 다시 파드를 생성하기 때문에 다운타임이 발생하지만, 추가 리소스를 사용하지 않고 전환이 빠른 것이 장점이다. Recreate의 경우 type 이외에 지정할 수 있는 항목은 없다.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sample-deployment-recreate
spec:
  strategy:
    type: Recreate
  replicas: 3
  selector:
    matchLabels:
      app: sample-app
  template:
    metadata:
      labels:
        app: sample-app
    spec:
      containers:
      - name: nginx-container
        image: nginx:1.16
```

```yaml
# 컨테이너 이미지 업데이트
kubectl set image deployment sample-deployment-recreate nginx-container=nginx:1.17

# 레플리카셋 목록 표시(리소스 상태에 변화가 있으면 계속 출력)
kubectl get replicasets --watch
```

### RollingUpdate

RollingUpdate는 업데이트 중에 동시에 정지 가능한 최대 파드 수(`maxUnavailable`)와 업데이트 중에 동시에 생성할 수 있는 최대 파드 수 (`maxSurge`)를 설정할 수 있다. 이 설정을 사용하면 추가 리소스를 사용하지 않도록 하거나 많은 리소스를 소비하지 않고 빠르게 전환하는 등 업데이트를 하면서 동작을 제어할 수 있다. `maxUnavailable`과 `maxSurge`를 모두 0으로 설정할 수는 없다.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sample-deployment-rollingupdate
spec:
  stragy:    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
  replicas: 3
  selector:
    matchLabels:
      app: sample-app
  template:
    metadata:
      labels:
        app: sample-app
    spec:
      containers:
      - name: nginx-container
        image: nginx:1.16
```

```yaml
# 컨테이너 이미지 업데이트
kubectl set image deployment sample-deployment-rollingupdate nginx-container=nginx:1.17

# 레플리카셋 목록 표시(리소스 상태에 변화가 있으면 계속 출력)
kubectl get replicasets --watch
```

<img width="1276" alt="2" src="https://github.com/user-attachments/assets/b8248b7f-a035-41f9-9343-c4481d85990c">

maxUnavailable=0/maxSurge=1 설정의 RollingUpdate에서는 maxSurge 수만큼 추가 레플리카 수를 늘려 파드를 이동시킨다. 그림으로 나타내면 아래와 같다.

<img width="1128" alt="3" src="https://github.com/user-attachments/assets/9ea9f857-f370-4db0-b0d8-90b16c71825d">

반대로 maxUnavailable=1/maxSurge=0 설정의 RollingUpdate에서는 maxUnavailable 수만큼 레플리카 수를 감소시킨 후 파드를 이동시킨다. 이 경우는 아래 그림과 같다.

<img width="1129" alt="4" src="https://github.com/user-attachments/assets/b3e7e0c5-f89e-40ae-8d50-7037d39a532f">

maxUnavailable과 maxSurge를 백분율로 지정할 수 있는데 지정하지 않을 경우 25%로 지정된다.

## 5.4.6 상세 업데이트 파라미터

Recreate나 RollingUpdate를 사용할 때 다른 파라미터를 설정하여 사용할 수도 있다.

- `minReadySeconds`
    - 최소 대기 시간(초)
    - 파드가 Ready 상태가 된 다음부터 디플로이먼트 리소스에서 파드 기동이 완료되었다고 판단(다음 파드의 교체가 가능하다고 판다)하기까지의 최소 시간(초)
- `revisionHistoryLimit`
    - 수정 버전 기록 제한
    - 디플로이먼트가 유지할 레플리카셋 수
    - 롤백이 가능한 이력 수
- `progressDeadlineSeconds`
    - 진행 기한 시간(초)
    - Recreate/RollingUpdate 처리 타임아웃 시간
    - 타임아웃 시간이 경과하면 자동으로 롤백
- 위 내용은 모두 디플로이먼트 spec 아래에서 설정할 수 있다.
    
    ```yaml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: sample-deployment-params
    spec:
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 0
          maxUnavailable: 1
        minReadySeconds: 0
        revionHistoryLimit: 2
        progressDeadlineSeconds: 3600
      replicas: 3
      selector:
        matchLabels:
          app: sample-app
      template:
        metadata:
          labels:
            app: sample-app
        spec:
          containers:
          - name: nginx-container
            image: nginx:1.16
    ```
    

## 5.4.7 디플로이먼트 스케일링

```yaml
# 레플리카 수를 3에서 4로 변경한 매니페스트를 apply
sed -i -e 's|replicas: 3|replicas: 4|' sample-deployment.yaml
kubectl apply -f sample-deployment.yaml

# kubectl scale 명령어를 사용한 스케일링
kubectl scale deployment sample-deployment --replicas=5
```

디플로이먼트가 관리하는 레플리카셋의 레플리카 수는 레플리카셋과 같은 방법으로 `kubectl apply -f` 또는 `kubectl scale`를 사용하여 스케일할 수 있다.

## 5.4.8 매니페스트를 사용하지 않고 디플로이먼트 생성

```yaml
# 매니페스트를 사용하지 않고 명령어로 디플로이먼트를 생성
kubectl create deployment sample-deployment-by-cli --image nginx:1.16
```

`kubectl create deployment` 명령어를 사용하면 매니페스트를 사용하지 않고 거의 동일한 디플로이먼트를 만들 수 있다.

기본 레이블은 `app: sample-deployment-by-cli`와 파드 템플릿 구조에서 계산되는 `pod-template-hash`가 부여되지만, 충돌 위험성이 낮아 이미지 확인 등의 간단한 작업 용도로 사용할 수 있다. 서비스 환경에서는 매니페스트를 사용하자.